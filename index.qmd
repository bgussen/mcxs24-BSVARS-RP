---
title: "Dixie Effect on Economic Stability in Australia"

author: "Ben Gussen"

execute:
  echo: false
  
bibliography: references.bib
---

> **Abstract.** This research project investigates the dynamic effects of the U.S. Dollar (USD) on the Australian economy, with a focus on economic stability. By employing Bayesian Structural Vector Autoregression (SVAR) analysis. This study aims to elucidate the transmission mechanisms of USD fluctuations through three channels: GDP growth, inflation, and unemployment. The findings are expected to provide nuanced insights into the macroeconomic interdependencies between the USD and the Australian economy, offering valuable perspectives for policymakers and economic analysts.
>
> **Keywords.** Bayesian SVAR, USD, Australian economy, inflation, economic stability

### Introduction

This document presents the design and implementation of a Bayesian Structural Vector Autoregression (SVAR) model. Our focus is on understanding the impact of the Trade Weighted Index (TWI) of the USD on Australian economic indicators: unemployment, inflation, and GDP rate.

### Research Proposal Structure

#### The Question, Objective, and Motivation

**Objective:** To examine the dynamic effects of a weakening USD on the Australian economy, focusing on changes to the GDP, inflation and unemployment.

**Research Question:** How does a weakening United States Dollar (USD) influence overall economic stability in Australia?

**Motivation:** The relationship between the USD and the Australian economy is crucial, given the extensive trade links and financial interactions between the two nations. In light of recent global financial uncertainties, understanding this interplay is essential for crafting informed economic policies and strategies. This research endeavors to dissect the complexities of this economic relationship, aiming to provide insights that could inform both policymakers and market participants.

#### The US dollar trade weighted index or the USD/AUD exchange rate?

@Chen2004 explores the impact of exchange rate movements on firm values in New Zealand, suggesting broader macroeconomic implications. Extending this analysis, @Chen2024 discusses the U.S. Dollar Index (USDX, DXY, "Dixie"), which measures the U.S. dollar's strength against a basket of major trading partner currencies. This index is vital for understanding the U.S. dollar's overall economic health and its global trade competitiveness.

Using the USD Index is preferred over the USD/AUD exchange rate because it provides a more comprehensive view of the US dollar's strength by comparing it against a basket of currencies from major trading partners. This broader perspective reflects overall trade competitiveness and economic impacts more accurately than the USD/AUD rate, which only measures the exchange value between two currencies. The USD Index, therefore, offers a better gauge of the US dollar's performance on a global scale, making it more suitable for analyzing its effect on the economic health of the Australian economy.

#### What is economic stability?

Economic stability indicates a nation's economy is in a healthy state, characterized by low and stable inflation, allowing for future financial planning without significant loss of purchasing power. It also involves a moderate unemployment rate, ensuring sufficient employment opportunities without causing wage inflation due to a limited labor pool. Additionally, the economy should experience steady growth with minor fluctuations in output, avoiding major booms and busts. Governments and central banks strive to maintain this stability using fiscal policies, such as taxation and spending, and monetary policies, including adjusting interest rates. Achieving economic stability is challenging as it requires maintaining a balance across various economic indicators. This stability is crucial as it enhances business confidence, boosts consumer spending, and supports overall economic health, with metrics like inflation, unemployment, and GDP growth serving as indicators of economic stability.

#### Effect of a weak US dollar on the Australian economy

A weaker US Dollar Index typically strengthens the Australian dollar, impacting the Australian economy in several ways:

1. **Inflation:** A stronger Australian dollar makes exports less competitive and imports cheaper, potentially decreasing export volumes while reducing inflation through lower import costs.

2. **Unemployment:** Reduced foreign investment due to a stronger Australian dollar could slow economic growth and potentially increase unemployment if businesses scale back expansion.

3. **GDP Growth:** The trade balance may suffer if reduced export revenues outweigh the benefits of cheaper imports, negatively impacting GDP growth.

### Data and Their Properties

In order to conduct a thorough analysis of the impact of USD fluctuations on the Australian economy, this study will utilize a set of time-series data that encapsulates three economic indicators:

- **Growth Rate in the Australian Gross Domestic Product:** Quarterly GDP figures representing the overall economic activity within Australia.

- **Unemployment Rate:** Percentage of the labor force that is currently unemployed and actively seeking employment.

- **Inflation Rate:** Measured by the change in the Consumer Price Index (CPI), reflecting the changes in prices for goods and services.

These indicators will be analyzed against one proxy for the strength of the USD dollar as an international currency. 

- **USD Trade Weighted Index:** monthly index of US dollar major currency trade-weighted index. 


#### Motivation for Data Choice:

The selected variables offer a detailed insight into the economic interactions between the US dollar and the Australian economy, focusing on how trade-weighted indices affect the competitiveness of Australian goods and services internationally. Changes in the US dollar's strength can significantly impact Australia's GDP growth, given the substantial trade relations with the United States. Additionally, fluctuations in this index are likely to alter inflation and unemployment rates, key indicators of economic stability that affect purchasing power and consumer spending. This comprehensive approach enables a thorough examination of the international economic dynamics and the overall stability of the Australian economy.

### Data Acquisition and Transformation:

The project will analyze data from 1980 to 2019 sourced from official Australian databases, particularly the Reserve Bank of Australia, focusing on the effects of a weakening USD on the Australian economy. Data from before 1980 and post-2019 are excluded due to their irrelevance to current trade relations and distortions from the COVID-19 crisis, respectively. The analysis will use time series data at different frequencies within a Bayesian Structural Vector Autoregression (SVAR) model, requiring preprocessing to match data frequencies.

For our purposes in this initial proposal, the required data will be sourced from official Australian government databases using the `readrba` R packages. Based on the preliminary results from the project, it might become necessary to entertain a mixed frequency approach. 

The first series, the year-end Australian real GDP growth rate, is from the Reserve Bank of Australia (RBA) output and labour statistical tables [@RBA2024a]. This is a quarterly series, and will not need to be treated for frequency alignment. 

```{r setup, include=FALSE}
#| echo: false
#| message: false
#| warning: false
library(readrba)
library(dplyr)
library(zoo)
library(lubridate)
library(tseries)
library(ggplot2)
library(urca)  # For conducting the ADF test
library(forecast) # For ACF and PACF plots 
library(gridExtra)
library(kableExtra)
library(MCMCpack)       # For Bayesian estimation
library(coda)           # For MCMC analysis
library(mvtnorm)        # For multivariate normal distributions
library(Matrix)         # For matrix operations
library(BVAR)
library(MASS)
```

```{r GDP growth rate}
#| echo: false
#| message: false
#| warning: false
#| label: fig-GDP
#| fig-cap: "ACF and PACF functions for the GDP growth rate"

# Downloading data from the internet
series <- read_rba(series_id = "GGDPCVGDPY")

#clean the series by removing missing values
series <- na.omit(series)

# Ensuring the date format is appropriate for quarterly data
series <- series %>% 
  mutate(date = as.yearqtr(date, format = "%Y-%q"))

# Filtering the dataset for the desired date range
GDP_rate <- series %>%
  filter(date >= as.yearqtr("1980 Q1") & date <= as.yearqtr("2019 Q4"))

# Set up the plotting area

par(mfrow=c(1,2))

# Plot ACF with lags limited to 10
acf(GDP_rate$value, main = "ACF for GDP Rate", lag.max = 10)
# Plot PACF with lags limited to 10
pacf(GDP_rate$value, main = "PACF for GDP Rate", lag.max = 10)
# Reset the plotting area back to default
par(mfrow=c(1, 1))
```

As seen in @fig-GDP, the PACF above, the optimal lag for conducting the augmented Dicky-Fuller (DF) test is 4. A summary of the results of this test can be found in the table below. 

```{r}
#| echo: false
#| message: false
#| warning: false

# Conduct the ADF test to check for stationarity
adf_test_result <- ur.df(GDP_rate$value, type = "drift", lags = 4, selectlags = "AIC")
```

Note that the augmented DF test suggests that the series is stationary at the 95% level. There is no need to modify the series. From the DF test results, its is safe to conclude that the GDP_rate series is stationary. 

The second series, the year-end change in Australian inflation rate, is from the Reserve Bank of Australia (RBA) inflation and inflation expectations statistical tables (@RBA2024b). This series has been converted from a monthly series into a quarterly series by choosing the relevant months for the beginning of each quarter, starting from March and ending with December. 

```{r CPI rate}
#| echo: false 
#| message: false
#| warning: false
#| label: fig-CPI
#| fig-cap: "ACF and PACF functions for the CPI rate"

## Downloading CPI data from the internet
series <- read_rba(series_id = "GCPIAGYP") 

#clean the series by removing missing values
series <- na.omit(series)

# Ensuring the date format is appropriate for quarterly data
series <- series %>% 
  mutate(date = as.yearqtr(date, format = "%Y-%q"))

# Ensuring that date is recognized as a quarterly object and summarizing to quarterly values
series_quarterly <- series %>% 
  mutate(quarter = as.yearqtr(date)) %>%
  group_by(quarter) %>%
  summarize(value = mean(value, na.rm = TRUE)) %>%
  ungroup()

# Filter for the correct range from Q1 1980 to Q4 2019
CPI_rate <- series_quarterly %>%
  filter(quarter >= as.yearqtr("1980 Q1") & quarter <= as.yearqtr("2019 Q4"))

# Set up the plotting area
par(mfrow=c(1, 2))

# Plot ACF with lags limited to 10
acf(CPI_rate$value, main = "ACF for CPI Rate", lag.max = 10)

# Plot PACF with lags limited to 10
pacf(CPI_rate$value, main = "PACF for CPI Rate", lag.max = 10)

# Reset the plotting area back to default
par(mfrow=c(1,1))

# Conduct the ADF test to check for stationarity
adf_test_result <- ur.df(CPI_rate$value, type = "drift", lags = 4, selectlags = "AIC")

```

From @fig-CPI, an augmented DF test was conducted with 3 lags. Note that the augmented DF test (see appendix) suggests that the series is not stationary at the 95% confidence level. There was a need to take the difference of the series.

The third series, the Australian unemployment rate, is from the Reserve Bank of Australia (RBA) output and labour Statistical tables [@RBA2024c]. This is  a monthly series. The series was converted into a quarterly series by choosing the relevant months for the beginning of each quarter, starting from March and ending with December. 

```{r unemp_rate}
#| echo: false 
#| message: false
#| warning: false
#| label: fig-unemp
#| fig-cap: "ACF and PACF functions for the unemployment rate"

## Downloading unemployment data from the internet
series <- read_rba(series_id = "GLFSURSA") 

#clean the series by removing missing values
series <- na.omit(series)

# Convert the date format from dd/mm/yyyy to Date object
series <- series %>% 
  mutate(date = as.Date(as.character(date), format = "%Y-%m-%d")) 

# Ensuring that date is recognized as a quarterly object and summarizing to quarterly values
series_quarterly <- series %>% 
  mutate(quarter = as.yearqtr(date)) %>%
  group_by(quarter) %>%
  summarize(value = mean(value, na.rm = TRUE)) %>%
  ungroup()

# Filter the series to start from the first quarter of 1980 and end in the last quarter of 2019
unemp_rate <- series_quarterly %>%
  filter(quarter >= as.yearqtr("1980 Q1") & quarter <= as.yearqtr("2019 Q4"))

# Set up the plotting area
par(mfrow=c(1, 2))

# Plot ACF with lags limited to 10
acf(unemp_rate$value, main = "ACF for Unemployment Rate", lag.max = 10)

# Plot PACF with lags limited to 10
pacf(unemp_rate$value, main = "PACF for Unemployment Rate", lag.max = 10)

# Reset the plotting area back to default
par(mfrow=c(1, 1))

# Conduct the ADF test to check for stationarity
adf_test_result <- ur.df(unemp_rate$value, type = "drift", lags = 4, selectlags = "AIC")



```

@fig-unemp above explains that a lag 4 should be used for the augmented DF test. Note that this test (see Appendix) suggests that the series is not stationary at the 95% confidence level. We therefore use the differenced series.

The fourth series, the USD Index, is also from the Reserve Bank of Australia (RBA) exchange rates statistical tables [@RBA2024d]. This is  a monthly series. The series was converted into a quarterly series by choosing the relevant months for the beginning of each quarter, starting from March and ending with December.

```{r USD Index}
#| echo: false
#| message: false
#| warning: false
#| label: fig-Index
#| fig-cap: "ACF and PACF functions for the USD Trade Weighted Index"

# Downloading USD Trade Weighted Index data from the internet (March 1973 = 100)

# Reading and preparing the USD TWI data
series <- read_rba(series_id = "FUSXRTWI") 

#clean the series by removing missing values
series <- na.omit(series)

# Convert the date format from dd/mm/yyyy to Date object
series <- series %>% 
  mutate(date = as.Date(as.character(date), format = "%Y-%m-%d")) 

# Ensuring that date is recognized as a quarterly object and summarizing to quarterly values
series_quarterly <- series %>% 
  mutate(quarter = as.yearqtr(date)) %>%
  group_by(quarter) %>%
  summarize(value = mean(value, na.rm = TRUE)) %>%
  ungroup()

# Filter the series to start from the first quarter of 1980 and end in the last quarter of 2019
USD_Index <- series_quarterly %>%
  filter(quarter >= as.yearqtr("1980 Q1") & quarter <= as.yearqtr("2019 Q4"))

# Apply logarithmic transformation to the USD Index values
USD_Index$value <- log(USD_Index$value)

# Set up the plotting area
par(mfrow=c(1, 2))

# Plot ACF with lags limited to 10
acf(unemp_rate$value, main = "ACF for USD Index", lag.max = 10)

# Plot PACF with lags limited to 10
pacf(unemp_rate$value, main = "PACF for USD Index", lag.max = 10)

# Reset the plotting area back to default
par(mfrow=c(1, 1))

# Augmented Dickey-Fuller test to check for stationarity
adf_test_result <- ur.df(USD_Index$value, type = "drift", lags = 4, selectlags = "AIC")



```

@fig-Index above indicates that a lag 4 should be used for the augmented DF test. The results suggest that the series is not stationary at the 95% confidence level. We therefore use the differenced series.

### Augmented Dicky-Fuller test results for the USD Index

```{r} 

# Load necessary libraries
library(tseries)
library(kableExtra)

# Prepare data for ADF tests
# Assuming data for GDP_rate, CPI_rate, unemp_rate, and USD_Index are already defined

# Perform ADF tests for each series
adf_results <- list(
  GDP = ur.df(GDP_rate$value, type = "drift", lags = 4),
  CPI = ur.df(CPI_rate$value, type = "drift", lags = 4),
  Unemployment = ur.df(unemp_rate$value, type = "drift", lags = 4),
  USD_Index = ur.df(USD_Index$value, type = "drift", lags = 4)
)

# Extracting test statistics and critical values
adf_summary <- sapply(adf_results, function(result) {
  c(
    Test_Statistic = result@teststat[1],  # Extract the test statistic
    Critical_Value_5pct = result@cval[1, "5pct"]  # Extract the 5% critical value
  )
})

# Convert the summary into a data frame for better formatting
adf_summary_df <- as.data.frame(t(adf_summary))
adf_summary_df$Variable <- rownames(adf_summary_df)

# Rearrange columns
adf_summary_df <- adf_summary_df[, c("Variable", "Test_Statistic", "Critical_Value_5pct")]

# Display the table
kable(adf_summary_df, caption = "ADF Test Results Summary") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))


```

### Do we need to use stationary data series

After consultations with Thomaz Wozniak, my understanding is that it is possible to use unit-root nonstationary variables in dynamic modeling. Based, on this, all rates are used without differencing, and the USD Index is used in logged form, also without differencing.

```{r plotting all four series}
#| echo: false
#| message: false
#| warning: false
#| label: fig-combined
#| fig-cap: "Treated series plots"


p1 <- ggplot(GDP_rate, aes(x = date, y = value)) +
  geom_line() +
  theme_minimal() +
  labs(title = "Quarterly GDP Rate (1980-2019)", x = "Quarter", y = "GDP Growth Rate (%)") +
  theme(plot.title = element_text(size = 9))

datasets <- list(CPI_rate = CPI_rate, unemp_rate = unemp_rate, USD_Index = USD_Index)
titles <- c("Quarterly CPI Rate (1980-2019)",
            "Quarterly Unemployment Rate (1980-2019)", "Log of Quarterly USD Index (1980-2019)")
y_titles <- c("CPI Rate (%)","Unemployment Rate (%)", 
              "Log(USD Index)")

# Empty list to store the plots
plot_list <- list()

# Loop over the datasets and titles
for (i in seq_along(datasets)) {
  # Create the plot
  plot <- ggplot(datasets[[i]], aes(x = quarter, y = value)) +
    geom_line() +
    theme_minimal() +
    labs(title = titles[i], x = "Quarter", y = y_titles[i]) +
    theme(plot.title = element_text(size = 9))
  
  # Add the plot to the list
  plot_list[[i]] <- plot
}

plot_list <- c(list(p1), plot_list)
grid.arrange(grobs = plot_list, ncol = 2)





```



### Model Specification


The above selection and treatment of the data is pivotal to answering the research question: How does a weakening United States Dollar (USD) influence overall economic stability in Australia? By focusing on key economic indicators like the GDP growth rate, unemployment rate, and inflation rate, and comparing these against the USD Trade Weighted Index (TWI), the study strategically addresses the multifaceted impact of USD fluctuations on the Australian economy. The chosen data encapsulate the essential aspects of economic stability, allowing for a nuanced analysis of the interdependencies between the USD's value and Australian economic health.

This approach is vital for constructing a comprehensive Bayesian Structural Vector Autoregression (SVAR) model. The SVAR model, designed to elucidate the transmission mechanisms of USD fluctuations, relies on accurate, time-aligned, and contextually relevant data to provide meaningful insights. By ensuring the data are stationary and appropriately preprocessed for the chosen analysis timeframe (1980-2019), excluding periods of atypical economic disruption like the COVID-19 crisis, the document ensures that the model's outputs are reflective of standard economic interactions, enhancing the reliability of the findings.

Furthermore, the data treatment, including the conversion of series to quarterly frequencies and addressing stationarity, directly informs the model equations by ensuring that the inputs reflect genuine economic trends devoid of seasonal or non-stationary noise. This data preparation not only strengthens the study’s methodological framework but also ensures that the SVAR model's findings will offer actionable insights, enabling policymakers and analysts to base decisions on solid empirical evidence, thereby underlining the importance of investigating the specified problem.

Next, we employ a Bayesian Structural Vector Autoregression (SVAR) model to understand the dynamic relationships among various economic indicators influenced by fluctuations in the United States Dollar (USD) against the Australian Dollar (AUD) [@wozniakBsvarsBayesianEstimation2022]. In particular, we follow @Bhuiyan2012 who introduces a Bayesian structural VAR model tailored for Canada, focusing on evaluating the impact of monetary policy shocks, utilizing the overnight rate target as the main policy tool. However, our model differs in that it does not directly account for any fiscal and monetary policy,  rather it evaluates the potential of using the US Index to predict the stability of the Australian economy. 

#### Justification for the Selection of the Bayesian SVAR Model

In addressing the dynamics between the United States Dollar (USD) and the Australian economy, we opt for a Bayesian Structural Vector Autoregression (SVAR) model over alternative econometric methodologies for several reasons. Firstly, the SVAR model allows us to incorporate prior knowledge and uncertainties into our analysis, an advantage not readily available in traditional VAR models. This Bayesian approach is particularly beneficial in economic studies where historical data and expert judgment play crucial roles in shaping analysis and expectations.

Furthermore, SVAR models enable us to decipher the structural impacts of economic shocks, such as fluctuations in the USD, on various indicators of economic stability within Australia, including GDP growth, inflation, and unemployment rates. Unlike standard VAR models that treat all innovations as endogenously generated within the system, SVAR models allow us to impose structural restrictions based on economic theory. This is critical for understanding the directionality and magnitude of relationships between variables, thereby offering a more nuanced analysis of economic interdependencies.

#### Interpretation of the $B_0$ Matrix in the Bayesian SVAR Model



For instance, a positive entry in the row of the GDP growth and in the column of the USD Index would indicate that an instantaneous increase in the USD Index (reflecting a strengthening of the USD) has a positive impact on Australian GDP growth within the same period. Such insights are invaluable for policymakers and analysts seeking to anticipate and mitigate the effects of international monetary fluctuations on domestic economic stability.

This is a 4x1 vector of endogenous variables at time t, where:

- $USD\_Index$ : Log of the Trade Weighted Index of the US Dollar.
- $Unemployment\_rate$ : unemployment rate.
- $Inflation\_rate$ : inflation rate.
- $GDP\_growth$ : growth rate of GDP.


The SVAR model structure:

- $B_0$ is a 4X4 matrix representing the contemporaneous relationships between the variables.
- $B_i$ (for i = 0,1,...,p) are 4x4 matrices representing the lagged effects (where p is the lag order).
- $u_t$ is a vector of innovations at time $t$, assumed to follow $u_t \mid Y_{t-1} \sim N(0, I_N)$, where $I_N$ is the identity matrix. This implies that shocks are independently and identically distributed with no correlation and a standard normal distribution.

LaTe

$$ 
Y_t =
\begin{bmatrix}
    USD\_Index_t \\
    Inflation\_rate_t \\
    Unemployment\_rate_t\\
    GDP\_growth_t
\end{bmatrix}
$$


The Bayesian Structural VAR model can then be written as: 

The Bayesian Structural Vector Autoregression (SVAR) model is given by the equation:

$$
B_0 Y_t = b_0 + B_1 Y_{t-1} + \dots + B_p Y_{t-p} + u_t
$$


#### Model Notations:

$Y_t$: This represents the vector of endogenous variables at time tt. In this context, the vector consists of the Trade Weighted Index of the US Dollar (USD_Index), the unemployment rate, the inflation rate, and the GDP growth rate. These variables are chosen because they represent key indicators of economic stability.

$B_0$: This is a matrix representing the contemporaneous relationships between the variables in $Y_t$. In an SVAR model, this matrix helps to understand how shocks to one variable (e.g., USD_Index) can contemporaneously affect other variables (e.g., unemployment, inflation, GDP growth).

$B_i$ (for i=0,1,...,pi=0,1,...,p): These are matrices representing the lagged effects of the variables on each other. The subscript ii represents the lag order, showing how past values (lags) of each variable in $Y_t$ influence the current values. In time series analysis, this captures dynamics such as how past economic conditions influence current outcomes.



#### Using the Model to Answer the Research Question:

The model will be used to analyze how fluctuations in the US Trade Weighted Index (representing a weakening or strengthening USD) impact the Australian economy's stability, specifically through GDP growth, inflation, and unemployment rates. By examining the contemporaneous and lagged relationships between these variables, we can understand the transmission mechanisms of US dollar fluctuations.

To address the research objectives, we will assess the dynamic effects of the USD_Index on Australia's economic indicators. This involves looking at the impulse response functions (IRFs) and variance decompositions derived from the SVAR model. The IRFs will show how a shock to the US dollar index impacts Australian GDP growth, inflation, and unemployment over time. This directly speaks to the study's aim to elucidate the transmission mechanisms of such fluctuations.

This analysis will be conducted using a stepwise approach:

- Lag Selection: Optimal lags for the variables will be determined based on the general approach in the literature for quarterly data, namely, 12 lags.

- Model Estimation: The extended SVAR model, incorporating the selected lags, will be estimated to analyze the interactions between the USD Index and Australian economic indicators.

#### Estimation Outputs for Interpreting the Research Question:

**Posterior Distributions**: These reflect the updated beliefs about the model's parameters after considering the data. We would examine the posterior distributions of the SVAR model parameters, particularly focusing on the coefficients that measure the impact of USD_Index changes on the economic indicators.

**Impulse Response Functions (IRFs)**: IRFs trace the effects of a one-time shock to one of the innovations on the current and future values of the endogenous variables. By analyzing the IRFs, we can interpret how an unexpected change in the US dollar's value affects Australian economic conditions over time.

**Variance Decompositions**: These help us understand the proportion of the forecast variance of each endogenous variable that can be attributed to shocks to each variable in the model, including shocks to the USD_Index. This is crucial for assessing the significance of US dollar fluctuations compared to other domestic factors.

**Credibility Intervals**: Unlike classical confidence intervals, credibility intervals in Bayesian analysis offer a probability statement about the parameter values. Examining these intervals for the effects of interest will provide insights into the certainty of our estimates.

In terms of economic context, understanding the relationship between the US dollar index and Australian economic indicators is vital for policymakers and economic analysts, especially considering the significant trade and financial ties between the two countries. The model helps address the research objectives by providing a structured way to quantify these relationships, thereby informing decisions that could enhance economic stability in response to international currency movements.

For your Bayesian SVAR model examining the impact of the U.S. Dollar on the Australian economy, applying exclusionary restrictions to the $B_0$ matrix can be guided by economic theory concerning the likely immediate (contemporaneous) effects of one variable on another. In the context of your study, focusing on GDP growth, inflation, and unemployment as responses to changes in the USD Trade Weighted Index, here are some suggestions for structuring these restrictions:

#### Considerations for $B_0$ Matrix Exclusionary Restrictions

Using a lower triangular matrix for $B_0$ in our Bayesian Structural Vector Autoregression (SVAR) model is a common approach in identifying the model. This approach can help ensure that the model is identified under the assumption that the contemporaneous relationships between the variables follow a specific causal ordering. Here's how we  implement and justify this approach along with leveraging the Minnesota prior for testing and imposing restrictions:

#### Using a Lower Triangular Matrix for $B_0$

##### Advantages
- **Causality Assumption**: A lower triangular matrix implies that a variable does not contemporaneously affect any variables that come before it in the ordering. This reflects a causal hierarchy among the variables, where earlier variables can affect later ones within the same time period, but not vice versa.
- **Model Identification**: SVAR models often suffer from identification issues due to the symmetric nature of the covariance matrix of the errors. Using a lower triangular $B_0$ can help in uniquely determining the model by providing a clear causal path among variables.

##### How to Implement
- **Ordering of Variables**: Decide the ordering of variables based on economic theory or empirical evidence. For our analysis on the effects of a weakening USD:
  1. **USD Index**: As the exogenous shock.
  2. **Inflation Rate**: Likely responds quickly to currency value changes due to import prices.
  3. **Unemployment Rate**: Might react to changes in economic conditions that are influenced by inflation adjustments.
  4. **GDP Growth**: Often considered to respond over a longer period to changes in broader economic indicators.
- **Matrix Structure**: With this ordering, our $B_0$ matrix would look like:

  $B_0 =$ 
  \begin{bmatrix}
    b_{11} & 0 & 0 & 0 \\
    b_{21} & b_{22} & 0 & 0 \\
    b_{31} & b_{32} & b_{33} & 0 \\
    b_{41} & b_{42} & b_{43} & b_{44}
  \end{bmatrix}

  Here, $b_{ij}$ are parameters to be estimated, with non-zero entries allowed only in the lower triangle, reflecting the immediate impacts as per the assumed causality.

#### Testing Restrictions Using the Minnesota Prior

##### Minnesota Prior and Shrinkage
- **Role of Minnesota Prior**: In Bayesian SVARs, the Minnesota prior typically imposes shrinkage on the parameters, pulling them towards some baseline values (often zero or a random walk hypothesis for autoregressive parameters). This can be particularly useful in imposing and testing exclusion restrictions implicitly through the prior distribution.
- **Implementing Shrinkage**: You can use the Minnesota prior to differentially shrink the off-diagonal elements of $B_0$ to test whether the data supports the exclusion restrictions. Larger shrinkage (higher prior variance) on certain parameters can test if the unrestricted model significantly deviates from these baseline assumptions.

##### Steps to Follow
1. **Specify the Prior**: Define your Minnesota prior for each element in $B_0$ based on how strongly you believe in the causal ordering and immediate impacts.
2. **Fit the Model**: Use Bayesian estimation techniques. We will use the Gibbs sampling proposed by @Waggoner&Zha2003 to fit the SVAR model.
3. **Analyze the Posterior**: Check the posterior distributions of the $B_0$ elements. If the posterior distributions of certain off-diagonal elements concentrate around zero (or within a close range), it supports the exclusion restrictions under the causal ordering.
4. **Robustness Checks**: Consider alternative orderings or less restrictive priors to ensure robustness of the findings.

This approach not only aids in model identification and ensures adherence to theoretical expectations but also leverages the flexibility of Bayesian methods to incorporate and test economic theory effectively.

### Bayesian estimation using MCMC


```{r prepare data for estimation (again)}
#| echo: false
#| message: false
#| warning: false

# Downloading data from the internet
series <- read_rba(series_id = "GGDPCVGDPY")

#clean the series by removing missing values
series <- na.omit(series)

# Ensuring the date format is appropriate for quarterly data
series <- series %>% 
  mutate(date = as.yearqtr(date, format = "%Y-%q"))

# Filtering the dataset for the desired date range
GDP_rate <- series %>%
  filter(date >= as.yearqtr("1980 Q1") & date <= as.yearqtr("2019 Q4"))

## Downloading CPI data from the internet
series <- read_rba(series_id = "GCPIAGYP") 

#clean the series by removing missing values
series <- na.omit(series)

# Ensuring the date format is appropriate for quarterly data
series <- series %>% 
  mutate(date = as.yearqtr(date, format = "%Y-%q"))

# Ensuring that date is recognized as a quarterly object and summarizing to quarterly values
series_quarterly <- series %>% 
  mutate(quarter = as.yearqtr(date)) %>%
  group_by(quarter) %>%
  summarize(value = mean(value, na.rm = TRUE)) %>%
  ungroup()

# Filter for the correct range from Q1 1980 to Q4 2019
CPI_rate <- series_quarterly %>%
  filter(quarter >= as.yearqtr("1980 Q1") & quarter <= as.yearqtr("2019 Q4"))

## Downloading unemployment data from the internet
series <- read_rba(series_id = "GLFSURSA") 

#clean the series by removing missing values
series <- na.omit(series)

# Convert the date format from dd/mm/yyyy to Date object
series <- series %>% 
  mutate(date = as.Date(as.character(date), format = "%Y-%m-%d")) 

# Ensuring that date is recognized as a quarterly object and summarizing to quarterly values
series_quarterly <- series %>% 
  mutate(quarter = as.yearqtr(date)) %>%
  group_by(quarter) %>%
  summarize(value = mean(value, na.rm = TRUE)) %>%
  ungroup()

# Filter the series to start from the first quarter of 1980 and end in the last quarter of 2019
unemp_rate <- series_quarterly %>%
  filter(quarter >= as.yearqtr("1980 Q1") & quarter <= as.yearqtr("2019 Q4"))

# Downloading USD Trade Weighted Index data from the internet (March 1973 = 100)

# Reading and preparing the USD TWI data
series <- read_rba(series_id = "FUSXRTWI") 

#clean the series by removing missing values
series <- na.omit(series)

# Convert the date format from dd/mm/yyyy to Date object
series <- series %>% 
  mutate(date = as.Date(as.character(date), format = "%Y-%m-%d")) 

# Ensuring that date is recognized as a quarterly object and summarizing to quarterly values
series_quarterly <- series %>% 
  mutate(quarter = as.yearqtr(date)) %>%
  group_by(quarter) %>%
  summarize(value = mean(value, na.rm = TRUE)) %>%
  ungroup()

# Filter the series to start from the first quarter of 1980 and end in the last quarter of 2019
USD_Index <- series_quarterly %>%
  filter(quarter >= as.yearqtr("1980 Q1") & quarter <= as.yearqtr("2019 Q4"))

# Apply logarithmic transformation to the USD Index values
USD_Index$value <- log(USD_Index$value)

```

```{r}

# Creating matrices Y and X

# Combining the data into one data frame
data <- data.frame(
  USD_Index = USD_Index$value, 
  Inflation = CPI_rate$value, 
  Unemployment = unemp_rate$value, 
  GDP_growth = GDP_rate$value
)

# Convert to a matrix Y
Y <- as.matrix(data)

# Define the number of lags
lags <- 1

# Manually shift the matrix to create lagged X
X <- Y[1:(nrow(Y) - lags), ]  # Get all rows up to the last 'lags' rows

# Adjust Y to match the new dimensions of X
Y <- Y[(lags + 1):nrow(Y), ]  # Start from row 'lags+1' to end

# Check the head of the matrices to ensure alignment
head(X)
head(Y)

```

```{r}

# Ensure matrices are numeric and aligned
Y <- as.matrix(Y)
X <- as.matrix(X)

# Define parameters for Bayesian estimation
burnin <- 10000
n_iter <- 50000

# Run separate MCMC regression for each variable in Y
results <- lapply(1:ncol(Y), function(i) {
  MCMCregress(Y[, i] ~ X - 1,  # No intercept since X includes lags and potentially a constant term
              b0 = rep(0, ncol(X)),    # Prior mean
              B0 = diag(0.01, ncol(X)),  # Prior precision (inverse of variance)
              mcmc = n_iter, burnin = burnin)
})

# To check the summary of results for each variable
summary_results <- lapply(results, summary)
summary_results




```
