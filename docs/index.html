<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.551">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ben Gussen">

<title>Dixie Effect on Economic Stability in Australia</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Dixie Effect on Economic Stability in Australia</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#research-proposal-structure" id="toc-research-proposal-structure" class="nav-link" data-scroll-target="#research-proposal-structure">Research Proposal Structure</a></li>
  <li><a href="#data-and-their-properties" id="toc-data-and-their-properties" class="nav-link" data-scroll-target="#data-and-their-properties">Data and Their Properties</a></li>
  <li><a href="#data-acquisition-and-transformation" id="toc-data-acquisition-and-transformation" class="nav-link" data-scroll-target="#data-acquisition-and-transformation">Data Acquisition and Transformation:</a></li>
  <li><a href="#augmented-dicky-fuller-test-results-for-the-usd-index" id="toc-augmented-dicky-fuller-test-results-for-the-usd-index" class="nav-link" data-scroll-target="#augmented-dicky-fuller-test-results-for-the-usd-index">Augmented Dicky-Fuller test results for the USD Index</a></li>
  <li><a href="#do-we-need-to-use-stationary-data-series" id="toc-do-we-need-to-use-stationary-data-series" class="nav-link" data-scroll-target="#do-we-need-to-use-stationary-data-series">Do we need to use stationary data series</a></li>
  <li><a href="#model-specification" id="toc-model-specification" class="nav-link" data-scroll-target="#model-specification">Model Specification</a></li>
  <li><a href="#derivation-of-the-estimation-algorithm" id="toc-derivation-of-the-estimation-algorithm" class="nav-link" data-scroll-target="#derivation-of-the-estimation-algorithm">Derivation of the Estimation Algorithm</a></li>
  <li><a href="#model-testing-using-a-random-walk" id="toc-model-testing-using-a-random-walk" class="nav-link" data-scroll-target="#model-testing-using-a-random-walk">Model Testing Using A Random Walk</a></li>
  <li><a href="#estimation-of-the-basic-model" id="toc-estimation-of-the-basic-model" class="nav-link" data-scroll-target="#estimation-of-the-basic-model">Estimation of the Basic Model</a></li>
  <li><a href="#model-extension-i-solving-the-identification-problem-using-a-non-normality-approach" id="toc-model-extension-i-solving-the-identification-problem-using-a-non-normality-approach" class="nav-link" data-scroll-target="#model-extension-i-solving-the-identification-problem-using-a-non-normality-approach">Model Extension I: Solving the Identification Problem Using a Non-Normality Approach</a></li>
  <li><a href="#step-1-formulating-the-kernel-of-the-likelihood-function" id="toc-step-1-formulating-the-kernel-of-the-likelihood-function" class="nav-link" data-scroll-target="#step-1-formulating-the-kernel-of-the-likelihood-function">Step 1: Formulating the Kernel of the Likelihood Function</a></li>
  <li><a href="#step-2-estimating-lambda" id="toc-step-2-estimating-lambda" class="nav-link" data-scroll-target="#step-2-estimating-lambda">Step 2: Estimating <span class="math inline">\(\lambda\)</span></a></li>
  <li><a href="#step-3-evaluating-the-kernel" id="toc-step-3-evaluating-the-kernel" class="nav-link" data-scroll-target="#step-3-evaluating-the-kernel">Step 3: Evaluating the Kernel</a></li>
  <li><a href="#step-4-combining-with-the-prior" id="toc-step-4-combining-with-the-prior" class="nav-link" data-scroll-target="#step-4-combining-with-the-prior">Step 4: Combining with the Prior</a></li>
  <li><a href="#second-extension-estimating-nu" id="toc-second-extension-estimating-nu" class="nav-link" data-scroll-target="#second-extension-estimating-nu">Second Extension: Estimating <span class="math inline">\(\nu\)</span></a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Dixie Effect on Economic Stability in Australia</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ben Gussen </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p><strong>Abstract.</strong> This research project investigates the dynamic effects of the U.S. Dollar (USD) on the Australian economy, with a focus on economic stability. By employing Bayesian Structural Vector Autoregression (SVAR) analysis. This study aims to elucidate the transmission mechanisms of USD fluctuations through three channels: GDP growth, inflation, and unemployment. The findings are expected to provide nuanced insights into the macroeconomic interdependencies between the USD and the Australian economy, offering valuable perspectives for policymakers and economic analysts.</p>
<p><strong>Keywords.</strong> Bayesian SVAR, USD, Australian economy, inflation, economic stability</p>
</blockquote>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>This document presents the design and implementation of a Bayesian Structural Vector Autoregression (SVAR) model. Our focus is on understanding the impact of the Trade Weighted Index (TWI) of the USD on Australian economic indicators: unemployment, inflation, and GDP rate.</p>
</section>
<section id="research-proposal-structure" class="level3">
<h3 class="anchored" data-anchor-id="research-proposal-structure">Research Proposal Structure</h3>
<section id="the-question-objective-and-motivation" class="level4">
<h4 class="anchored" data-anchor-id="the-question-objective-and-motivation">The Question, Objective, and Motivation</h4>
<p><strong>Objective:</strong> To examine the dynamic effects of a weakening USD on the Australian economy, focusing on changes to the GDP, inflation and unemployment.</p>
<p><strong>Research Question:</strong> How does a weakening United States Dollar (USD) influence overall economic stability in Australia?</p>
<p><strong>Motivation:</strong> The relationship between the USD and the Australian economy is crucial, given the extensive trade links and financial interactions between the two nations. In light of recent global financial uncertainties, understanding this interplay is essential for crafting informed economic policies and strategies. This research endeavors to dissect the complexities of this economic relationship, aiming to provide insights that could inform both policymakers and market participants.</p>
</section>
<section id="the-us-dollar-trade-weighted-index-or-the-usdaud-exchange-rate" class="level4">
<h4 class="anchored" data-anchor-id="the-us-dollar-trade-weighted-index-or-the-usdaud-exchange-rate">The US dollar trade weighted index or the USD/AUD exchange rate?</h4>
<p><span class="citation" data-cites="Chen2004">Chen J., Naylor, and Lu (<a href="#ref-Chen2004" role="doc-biblioref">2004</a>)</span> explores the impact of exchange rate movements on firm values in New Zealand, suggesting broader macroeconomic implications. Extending this analysis, <span class="citation" data-cites="Chen2024">J. Chen (<a href="#ref-Chen2024" role="doc-biblioref">2024</a>)</span> discusses the U.S. Dollar Index (USDX, DXY, “Dixie”), which measures the U.S. dollar’s strength against a basket of major trading partner currencies. This index is vital for understanding the U.S. dollar’s overall economic health and its global trade competitiveness.</p>
<p>Using the USD Index is preferred over the USD/AUD exchange rate because it provides a more comprehensive view of the US dollar’s strength by comparing it against a basket of currencies from major trading partners. This broader perspective reflects overall trade competitiveness and economic impacts more accurately than the USD/AUD rate, which only measures the exchange value between two currencies. The USD Index, therefore, offers a better gauge of the US dollar’s performance on a global scale, making it more suitable for analyzing its effect on the economic health of the Australian economy.</p>
</section>
<section id="what-is-economic-stability" class="level4">
<h4 class="anchored" data-anchor-id="what-is-economic-stability">What is economic stability?</h4>
<p>Economic stability indicates a nation’s economy is in a healthy state, characterized by low and stable inflation, allowing for future financial planning without significant loss of purchasing power. It also involves a moderate unemployment rate, ensuring sufficient employment opportunities without causing wage inflation due to a limited labor pool. Additionally, the economy should experience steady growth with minor fluctuations in output, avoiding major booms and busts. Governments and central banks strive to maintain this stability using fiscal policies, such as taxation and spending, and monetary policies, including adjusting interest rates. Achieving economic stability is challenging as it requires maintaining a balance across various economic indicators. This stability is crucial as it enhances business confidence, boosts consumer spending, and supports overall economic health, with metrics like inflation, unemployment, and GDP growth serving as indicators of economic stability.</p>
</section>
<section id="effect-of-a-weak-us-dollar-on-the-australian-economy" class="level4">
<h4 class="anchored" data-anchor-id="effect-of-a-weak-us-dollar-on-the-australian-economy">Effect of a weak US dollar on the Australian economy</h4>
<p>A weaker US Dollar Index typically strengthens the Australian dollar, impacting the Australian economy in several ways:</p>
<ol type="1">
<li><p><strong>Inflation:</strong> A stronger Australian dollar makes exports less competitive and imports cheaper, potentially decreasing export volumes while reducing inflation through lower import costs.</p></li>
<li><p><strong>Unemployment:</strong> Reduced foreign investment due to a stronger Australian dollar could slow economic growth and potentially increase unemployment if businesses scale back expansion.</p></li>
<li><p><strong>GDP Growth:</strong> The trade balance may suffer if reduced export revenues outweigh the benefits of cheaper imports, negatively impacting GDP growth.</p></li>
</ol>
</section>
</section>
<section id="data-and-their-properties" class="level3">
<h3 class="anchored" data-anchor-id="data-and-their-properties">Data and Their Properties</h3>
<p>In order to conduct a thorough analysis of the impact of USD fluctuations on the Australian economy, this study will utilize a set of time-series data that encapsulates three economic indicators:</p>
<ul>
<li><p><strong>Growth Rate in the Australian Gross Domestic Product:</strong> Quarterly GDP figures representing the overall economic activity within Australia.</p></li>
<li><p><strong>Unemployment Rate:</strong> Percentage of the labor force that is currently unemployed and actively seeking employment.</p></li>
<li><p><strong>Inflation Rate:</strong> Measured by the change in the Consumer Price Index (CPI), reflecting the changes in prices for goods and services.</p></li>
</ul>
<p>These indicators will be analyzed against one proxy for the strength of the USD dollar as an international currency.</p>
<ul>
<li><strong>USD Trade Weighted Index:</strong> monthly index of US dollar major currency trade-weighted index.</li>
</ul>
<section id="motivation-for-data-choice" class="level4">
<h4 class="anchored" data-anchor-id="motivation-for-data-choice">Motivation for Data Choice:</h4>
<p>The selected variables offer a detailed insight into the economic interactions between the US dollar and the Australian economy, focusing on how trade-weighted indices affect the competitiveness of Australian goods and services internationally. Changes in the US dollar’s strength can significantly impact Australia’s GDP growth, given the substantial trade relations with the United States. Additionally, fluctuations in this index are likely to alter inflation and unemployment rates, key indicators of economic stability that affect purchasing power and consumer spending. This comprehensive approach enables a thorough examination of the international economic dynamics and the overall stability of the Australian economy.</p>
</section>
</section>
<section id="data-acquisition-and-transformation" class="level3">
<h3 class="anchored" data-anchor-id="data-acquisition-and-transformation">Data Acquisition and Transformation:</h3>
<p>The project will analyze data from 1980 to 2019 sourced from official Australian databases, particularly the Reserve Bank of Australia, focusing on the effects of a weakening USD on the Australian economy. Data from before 1980 and post-2019 are excluded due to their irrelevance to current trade relations and distortions from the COVID-19 crisis, respectively. The analysis will use time series data at different frequencies within a Bayesian Structural Vector Autoregression (SVAR) model, requiring preprocessing to match data frequencies.</p>
<p>For our purposes in this initial proposal, the required data will be sourced from official Australian government databases using the <code>readrba</code> R packages. Based on the preliminary results from the project, it might become necessary to entertain a mixed frequency approach.</p>
<p>The first series, the year-end Australian real GDP growth rate, is from the Reserve Bank of Australia (RBA) output and labour statistical tables <span class="citation" data-cites="RBA2024a">(<a href="#ref-RBA2024a" role="doc-biblioref">Reserve Bank of Australia 2024c</a>)</span>. This is a quarterly series, and will not need to be treated for frequency alignment.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-GDP" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-GDP-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-GDP-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-GDP-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: ACF and PACF functions for the GDP growth rate
</figcaption>
</figure>
</div>
</div>
</div>
<p>As seen in <a href="#fig-GDP" class="quarto-xref">Figure&nbsp;1</a>, the PACF above, the optimal lag for conducting the augmented Dicky-Fuller (DF) test is 4. A summary of the results of this test can be found in the table below.</p>
<p>Note that the augmented DF test suggests that the series is stationary at the 95% level. There is no need to modify the series. From the DF test results, its is safe to conclude that the GDP_rate series is stationary.</p>
<p>The second series, the year-end change in Australian inflation rate, is from the Reserve Bank of Australia (RBA) inflation and inflation expectations statistical tables (<span class="citation" data-cites="RBA2024b">Reserve Bank of Australia (<a href="#ref-RBA2024b" role="doc-biblioref">2024d</a>)</span>). This series has been converted from a monthly series into a quarterly series by choosing the relevant months for the beginning of each quarter, starting from March and ending with December.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-CPI" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-CPI-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-CPI-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-CPI-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: ACF and PACF functions for the CPI rate
</figcaption>
</figure>
</div>
</div>
</div>
<p>From <a href="#fig-CPI" class="quarto-xref">Figure&nbsp;2</a>, an augmented DF test was conducted with 3 lags. Note that the augmented DF test suggests that the series is not stationary at the 95% confidence level. There was a need to take the difference of the series.</p>
<p>The third series, the Australian unemployment rate, is from the Reserve Bank of Australia (RBA) output and labour Statistical tables <span class="citation" data-cites="RBA2024c">(<a href="#ref-RBA2024c" role="doc-biblioref">Reserve Bank of Australia 2024b</a>)</span>. This is a monthly series. The series was converted into a quarterly series by choosing the relevant months for the beginning of each quarter, starting from March and ending with December.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-unemp" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-unemp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-unemp-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-unemp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: ACF and PACF functions for the unemployment rate
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-unemp" class="quarto-xref">Figure&nbsp;3</a> above explains that a lag 4 should be used for the augmented DF test. Note that this test (see Appendix) suggests that the series is not stationary at the 95% confidence level. We therefore use the differenced series.</p>
<p>The fourth series, the USD Index, is also from the Reserve Bank of Australia (RBA) exchange rates statistical tables <span class="citation" data-cites="RBA2024d">(<a href="#ref-RBA2024d" role="doc-biblioref">Reserve Bank of Australia 2024a</a>)</span>. This is a monthly series. The series was converted into a quarterly series by choosing the relevant months for the beginning of each quarter, starting from March and ending with December.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-Index" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-Index-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-Index-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-Index-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: ACF and PACF functions for the USD Trade Weighted Index
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-Index" class="quarto-xref">Figure&nbsp;4</a> above indicates that a lag 4 should be used for the augmented DF test. The results suggest that the series is not stationary at the 95% confidence level. We therefore use the differenced series.</p>
</section>
<section id="augmented-dicky-fuller-test-results-for-the-usd-index" class="level3">
<h3 class="anchored" data-anchor-id="augmented-dicky-fuller-test-results-for-the-usd-index">Augmented Dicky-Fuller test results for the USD Index</h3>
<div class="cell">
<div class="cell-output-display">
<div>
<table class="table table-striped table-hover table-sm small" data-quarto-postprocess="true">
<caption>ADF Test Results Summary</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Variable</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Test_Statistic</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Critical_Value_5pct</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">GDP</td>
<td style="text-align: left;">GDP</td>
<td style="text-align: right;">-3.872311</td>
<td style="text-align: right;">-2.88</td>
</tr>
<tr class="even">
<td style="text-align: left;">CPI</td>
<td style="text-align: left;">CPI</td>
<td style="text-align: right;">-2.262783</td>
<td style="text-align: right;">-2.88</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Unemployment</td>
<td style="text-align: left;">Unemployment</td>
<td style="text-align: right;">-1.928571</td>
<td style="text-align: right;">-2.88</td>
</tr>
<tr class="even">
<td style="text-align: left;">USD_Index</td>
<td style="text-align: left;">USD_Index</td>
<td style="text-align: right;">-1.930479</td>
<td style="text-align: right;">-2.88</td>
</tr>
</tbody>
</table>


</div>
</div>
</div>
</section>
<section id="do-we-need-to-use-stationary-data-series" class="level3">
<h3 class="anchored" data-anchor-id="do-we-need-to-use-stationary-data-series">Do we need to use stationary data series</h3>
<p>After consultations with Dr.&nbsp;Thomaz Wozniak, my understanding is that it is possible to use unit-root nonstationary variables in dynamic modeling. Based, on this, all rates are used without differencing, and the USD Index is used in logged form, also without differencing.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-combined" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-combined-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-combined-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-combined-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Treated series plots
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="model-specification" class="level3">
<h3 class="anchored" data-anchor-id="model-specification">Model Specification</h3>
<p>The above selection and treatment of the data is pivotal to answering the research question: How does a weakening United States Dollar (USD) influence overall economic stability in Australia? By focusing on key economic indicators like the GDP growth rate, unemployment rate, and inflation rate, and comparing these against the USD Trade Weighted Index (TWI), the study strategically addresses the multifaceted impact of USD fluctuations on the Australian economy. The chosen data encapsulate the essential aspects of economic stability, allowing for a nuanced analysis of the interdependencies between the USD’s value and Australian economic health.</p>
<p>This approach is vital for constructing a comprehensive Bayesian Structural Vector Autoregression (SVAR) model. The SVAR model, designed to elucidate the transmission mechanisms of USD fluctuations, relies on accurate, time-aligned, and contextually relevant data to provide meaningful insights. By ensuring the data are stationary and appropriately preprocessed for the chosen analysis timeframe (1980-2019), excluding periods of atypical economic disruption like the COVID-19 crisis, the document ensures that the model’s outputs are reflective of standard economic interactions, enhancing the reliability of the findings.</p>
<p>Furthermore, the data treatment, including the conversion of series to quarterly frequencies and addressing stationarity, directly informs the model equations by ensuring that the inputs reflect genuine economic trends devoid of seasonal or non-stationary noise. This data preparation not only strengthens the study’s methodological framework but also ensures that the SVAR model’s findings will offer actionable insights, enabling policymakers and analysts to base decisions on solid empirical evidence, thereby underlining the importance of investigating the specified problem.</p>
<p>Next, we employ a Bayesian Structural Vector Autoregression (SVAR) model to understand the dynamic relationships among various economic indicators influenced by fluctuations in the United States Dollar (USD) against the Australian Dollar (AUD) <span class="citation" data-cites="wozniakBsvarsBayesianEstimation2022">(<a href="#ref-wozniakBsvarsBayesianEstimation2022" role="doc-biblioref">Woźniak 2022</a>)</span>. In particular, we follow <span class="citation" data-cites="Bhuiyan2012">Bhuiyan (<a href="#ref-Bhuiyan2012" role="doc-biblioref">2012</a>)</span> who introduces a Bayesian structural VAR model tailored for Canada, focusing on evaluating the impact of monetary policy shocks, utilizing the overnight rate target as the main policy tool. However, our model differs in that it does not directly account for any fiscal and monetary policy, rather it evaluates the potential of using the US Index to predict the stability of the Australian economy.</p>
<section id="justification-for-the-selection-of-the-bayesian-svar-model" class="level4">
<h4 class="anchored" data-anchor-id="justification-for-the-selection-of-the-bayesian-svar-model">Justification for the Selection of the Bayesian SVAR Model</h4>
<p>In addressing the dynamics between the United States Dollar (USD) and the Australian economy, we opt for a Bayesian Structural Vector Autoregression (SVAR) model over alternative econometric methodologies for several reasons. Firstly, the SVAR model allows us to incorporate prior knowledge and uncertainties into our analysis, an advantage not readily available in traditional VAR models. This Bayesian approach is particularly beneficial in economic studies where historical data and expert judgment play crucial roles in shaping analysis and expectations.</p>
<p>Furthermore, SVAR models enable us to decipher the structural impacts of economic shocks, such as fluctuations in the USD, on various indicators of economic stability within Australia, including GDP growth, inflation, and unemployment rates. Unlike standard VAR models that treat all innovations as endogenously generated within the system, SVAR models allow us to impose structural restrictions based on economic theory. This is critical for understanding the directionality and magnitude of relationships between variables, thereby offering a more nuanced analysis of economic interdependencies.</p>
</section>
<section id="interpretation-of-the-b_0-matrix-in-the-bayesian-svar-model" class="level4">
<h4 class="anchored" data-anchor-id="interpretation-of-the-b_0-matrix-in-the-bayesian-svar-model">Interpretation of the <span class="math inline">\(B_0\)</span> Matrix in the Bayesian SVAR Model</h4>
<p>In our Bayesian SVAR model, the matrix <span class="math inline">\(B_0\)</span> is pivotal as it encapsulates the contemporaneous relationships between the endogenous variables. Each entry <span class="math inline">\(b_{ij}\)</span> in the <span class="math inline">\(B_0\)</span> matrix can be interpreted as the immediate impact of a one-unit shock in variable <span class="math inline">\(j\)</span> on variable <span class="math inline">\(i\)</span> within the same time period, holding all other factors constant. This interpretation allows us to understand the intricate web of interactions within the economic system, such as how a sudden change in the USD Index might immediately affect Australia’s GDP growth, inflation, or unemployment rate.</p>
<p>For instance, a positive entry in the row of the GDP growth and in the column of the USD Index would indicate that an instantaneous increase in the USD Index (reflecting a strengthening of the USD) has a positive impact on Australian GDP growth within the same period. Such insights are invaluable for policymakers and analysts seeking to anticipate and mitigate the effects of international monetary fluctuations on domestic economic stability.</p>
<p>This is a 4x1 vector of endogenous variables at time t, where:</p>
<ul>
<li><span class="math inline">\(USD\_Index\)</span> : Log of the Trade Weighted Index of the US Dollar.</li>
<li><span class="math inline">\(Unemployment\_rate\)</span> : unemployment rate.</li>
<li><span class="math inline">\(Inflation\_rate\)</span> : inflation rate.</li>
<li><span class="math inline">\(GDP\_growth\)</span> : growth rate of GDP.</li>
</ul>
<p>The SVAR model structure:</p>
<ul>
<li><span class="math inline">\(B_0\)</span> is a 4X4 matrix representing the contemporaneous relationships between the variables.</li>
<li><span class="math inline">\(B_i\)</span> (for i = 0,1,…,p) are 4x4 matrices representing the lagged effects (where p is the lag order).</li>
<li><span class="math inline">\(u_t\)</span> is a vector of innovations at time <span class="math inline">\(t\)</span>, assumed to follow <span class="math inline">\(u_t \mid Y_{t-1} \sim N(0, I_N)\)</span>, where <span class="math inline">\(I_N\)</span> is the identity matrix. This implies that shocks are independently and identically distributed with no correlation and a standard normal distribution.</li>
</ul>
<p><span class="math display">\[
Y_t =
\begin{bmatrix}
    USD\_Index_t \\
    Inflation\_rate_t \\
    Unemployment\_rate_t\\
    GDP\_growth_t
\end{bmatrix}
\]</span></p>
<p>The Bayesian Structural VAR model can then be written as:</p>
<p>The Bayesian Structural Vector Autoregression (SVAR) model is given by the equation:</p>
<p><span class="math display">\[
B_0 Y_t = b_0 + B_1 Y_{t-1} + \dots + B_p Y_{t-p} + u_t
\]</span></p>
</section>
<section id="model-notations" class="level4">
<h4 class="anchored" data-anchor-id="model-notations">Model Notations:</h4>
<p><span class="math inline">\(Y_t\)</span>: This represents the vector of endogenous variables at time tt. In this context, the vector consists of the Trade Weighted Index of the US Dollar (USD_Index), the unemployment rate, the inflation rate, and the GDP growth rate. These variables are chosen because they represent key indicators of economic stability.</p>
<p><span class="math inline">\(B_0\)</span>: This is a matrix representing the contemporaneous relationships between the variables in <span class="math inline">\(Y_t\)</span>. In an SVAR model, this matrix helps to understand how shocks to one variable (e.g., USD_Index) can contemporaneously affect other variables (e.g., unemployment, inflation, GDP growth).</p>
<p><span class="math inline">\(B_i\)</span> (for i=0,1,…,pi=0,1,…,p): These are matrices representing the lagged effects of the variables on each other. The subscript ii represents the lag order, showing how past values (lags) of each variable in <span class="math inline">\(Y_t\)</span> influence the current values. In time series analysis, this captures dynamics such as how past economic conditions influence current outcomes.</p>
<p><span class="math inline">\(u_t\)</span>: This is the vector of errors or shocks at time tt. In the SVAR framework, these are considered unobservable random shocks that affect the endogenous variables. In Bayesian SVAR models, these shocks are also subjected to prior distributions reflecting our beliefs or assumptions before observing the data.</p>
</section>
<section id="using-the-model-to-answer-the-research-question" class="level4">
<h4 class="anchored" data-anchor-id="using-the-model-to-answer-the-research-question">Using the Model to Answer the Research Question:</h4>
<p>The model will be used to analyze how fluctuations in the US Trade Weighted Index (representing a weakening or strengthening USD) impact the Australian economy’s stability, specifically through GDP growth, inflation, and unemployment rates. By examining the contemporaneous and lagged relationships between these variables, we can understand the transmission mechanisms of US dollar fluctuations.</p>
<p>To address the research objectives, we will assess the dynamic effects of the USD_Index on Australia’s economic indicators. This involves looking at the impulse response functions (IRFs) and variance decompositions derived from the SVAR model. The IRFs will show how a shock to the US dollar index impacts Australian GDP growth, inflation, and unemployment over time. This directly speaks to the study’s aim to elucidate the transmission mechanisms of such fluctuations.</p>
<p>This analysis will be conducted using a stepwise approach:</p>
<ul>
<li><p>Lag Selection: Optimal lags for the variables will be determined based on the general approach in the literature for quarterly data, namely, 12 lags.</p></li>
<li><p>Model Estimation: The extended SVAR model, incorporating the selected lags, will be estimated to analyze the interactions between the USD Index and Australian economic indicators.</p></li>
</ul>
</section>
<section id="estimation-outputs-for-interpreting-the-research-question" class="level4">
<h4 class="anchored" data-anchor-id="estimation-outputs-for-interpreting-the-research-question">Estimation Outputs for Interpreting the Research Question:</h4>
<p><strong>Posterior Distributions</strong>: These reflect the updated beliefs about the model’s parameters after considering the data. We would examine the posterior distributions of the SVAR model parameters, particularly focusing on the coefficients that measure the impact of USD_Index changes on the economic indicators.</p>
<p><strong>Impulse Response Functions (IRFs)</strong>: IRFs trace the effects of a one-time shock to one of the innovations on the current and future values of the endogenous variables. By analyzing the IRFs, we can interpret how an unexpected change in the US dollar’s value affects Australian economic conditions over time.</p>
<p><strong>Variance Decompositions</strong>: These help us understand the proportion of the forecast variance of each endogenous variable that can be attributed to shocks to each variable in the model, including shocks to the USD_Index. This is crucial for assessing the significance of US dollar fluctuations compared to other domestic factors.</p>
<p><strong>Credibility Intervals</strong>: Unlike classical confidence intervals, credibility intervals in Bayesian analysis offer a probability statement about the parameter values. Examining these intervals for the effects of interest will provide insights into the certainty of our estimates.</p>
<p>In terms of economic context, understanding the relationship between the US dollar index and Australian economic indicators is vital for policymakers and economic analysts, especially considering the significant trade and financial ties between the two countries. The model helps address the research objectives by providing a structured way to quantify these relationships, thereby informing decisions that could enhance economic stability in response to international currency movements.</p>
<p>For your Bayesian SVAR model examining the impact of the U.S. Dollar on the Australian economy, applying exclusionary restrictions to the <span class="math inline">\(B_0\)</span> matrix can be guided by economic theory concerning the likely immediate (contemporaneous) effects of one variable on another. In the context of your study, focusing on GDP growth, inflation, and unemployment as responses to changes in the USD Trade Weighted Index, here are some suggestions for structuring these restrictions:</p>
</section>
<section id="considerations-for-b_0-matrix-exclusionary-restrictions" class="level4">
<h4 class="anchored" data-anchor-id="considerations-for-b_0-matrix-exclusionary-restrictions">Considerations for <span class="math inline">\(B_0\)</span> Matrix Exclusionary Restrictions</h4>
<p>Using a lower triangular matrix for <span class="math inline">\(B_0\)</span> in our Bayesian Structural Vector Autoregression (SVAR) model is a common approach in identifying the model. This approach can help ensure that the model is identified under the assumption that the contemporaneous relationships between the variables follow a specific causal ordering. Here’s how we implement and justify this approach along with leveraging the Minnesota prior for testing and imposing restrictions:</p>
</section>
<section id="using-a-lower-triangular-matrix-for-b_0" class="level4">
<h4 class="anchored" data-anchor-id="using-a-lower-triangular-matrix-for-b_0">Using a Lower Triangular Matrix for <span class="math inline">\(B_0\)</span></h4>
<section id="advantages" class="level5">
<h5 class="anchored" data-anchor-id="advantages">Advantages</h5>
<ul>
<li><strong>Causality Assumption</strong>: A lower triangular matrix implies that a variable does not contemporaneously affect any variables that come before it in the ordering. This reflects a causal hierarchy among the variables, where earlier variables can affect later ones within the same time period, but not vice versa.</li>
<li><strong>Model Identification</strong>: SVAR models often suffer from identification issues due to the symmetric nature of the covariance matrix of the errors. Using a lower triangular <span class="math inline">\(B_0\)</span> can help in uniquely determining the model by providing a clear causal path among variables.</li>
</ul>
</section>
<section id="how-to-implement" class="level5">
<h5 class="anchored" data-anchor-id="how-to-implement">How to Implement</h5>
<ul>
<li><p><strong>Ordering of Variables</strong>: Decide the ordering of variables based on economic theory or empirical evidence. For our analysis on the effects of a weakening USD:</p>
<ol type="1">
<li><strong>USD Index</strong>: As the exogenous shock.</li>
<li><strong>Inflation Rate</strong>: Likely responds quickly to currency value changes due to import prices.</li>
<li><strong>Unemployment Rate</strong>: Might react to changes in economic conditions that are influenced by inflation adjustments.</li>
<li><strong>GDP Growth</strong>: Often considered to respond over a longer period to changes in broader economic indicators.</li>
</ol></li>
<li><p><strong>Matrix Structure</strong>: With this ordering, our <span class="math inline">\(B_0\)</span> matrix would look like:</p>
<p><span class="math inline">\(B_0 =\)</span></p>
<span class="math display">\[\begin{bmatrix}
  b_{11} &amp; 0 &amp; 0 &amp; 0 \\
  b_{21} &amp; b_{22} &amp; 0 &amp; 0 \\
  b_{31} &amp; b_{32} &amp; b_{33} &amp; 0 \\
  b_{41} &amp; b_{42} &amp; b_{43} &amp; b_{44}
\end{bmatrix}\]</span>
<p>Here, <span class="math inline">\(b_{ij}\)</span> are parameters to be estimated, with non-zero entries allowed only in the lower triangle, reflecting the immediate impacts as per the assumed causality.</p></li>
</ul>
</section>
</section>
<section id="testing-restrictions-using-the-minnesota-prior" class="level4">
<h4 class="anchored" data-anchor-id="testing-restrictions-using-the-minnesota-prior">Testing Restrictions Using the Minnesota Prior</h4>
<section id="minnesota-prior-and-shrinkage" class="level5">
<h5 class="anchored" data-anchor-id="minnesota-prior-and-shrinkage">Minnesota Prior and Shrinkage</h5>
<ul>
<li><strong>Role of Minnesota Prior</strong>: In Bayesian SVARs, the Minnesota prior typically imposes shrinkage on the parameters, pulling them towards some baseline values (often zero or a random walk hypothesis for autoregressive parameters). This can be particularly useful in imposing and testing exclusion restrictions implicitly through the prior distribution.</li>
<li><strong>Implementing Shrinkage</strong>: We use the Minnesota prior to differentially shrink the off-diagonal elements of <span class="math inline">\(B_0\)</span> to test whether the data supports the exclusion restrictions. Larger shrinkage (higher prior variance) on certain parameters can test if the unrestricted model significantly deviates from these baseline assumptions.</li>
</ul>
</section>
<section id="steps-to-follow" class="level5">
<h5 class="anchored" data-anchor-id="steps-to-follow">Steps to Follow</h5>
<ol type="1">
<li><strong>Specify the Prior</strong>: Define the Minnesota prior for each element in <span class="math inline">\(B_0\)</span> based on how strongly our believe in the causal ordering and immediate impacts.</li>
<li><strong>Fit the Model</strong>: Use Bayesian estimation techniques. We will use the Gibbs sampling proposed by <span class="citation" data-cites="Waggoner&amp;Zha2003">Waggoner and Zha (<a href="#ref-Waggoner&amp;Zha2003" role="doc-biblioref">2003</a>)</span> to fit the SVAR model.</li>
<li><strong>Analyze the Posterior</strong>: Check the posterior distributions of the <span class="math inline">\(B_0\)</span> elements. If the posterior distributions of certain off-diagonal elements concentrate around zero (or within a close range), it supports the exclusion restrictions under the causal ordering.</li>
<li><strong>Robustness Checks</strong>: Consider alternative orderings or less restrictive priors to ensure robustness of the findings.</li>
</ol>
<p>This approach not only aids in model identification and ensures adherence to theoretical expectations but also leverages the flexibility of Bayesian methods to incorporate and test economic theory effectively.</p>
</section>
</section>
</section>
<section id="derivation-of-the-estimation-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="derivation-of-the-estimation-algorithm">Derivation of the Estimation Algorithm</h3>
<p>For the basic model as described above, we will proceed as follows:</p>
<section id="model-structure" class="level4">
<h4 class="anchored" data-anchor-id="model-structure">Model Structure</h4>
<p>The SVAR model is expressed as: <span class="math inline">\(B_0 Y_t = B_+ X_t + u_t\)</span> where: - <span class="math inline">\(B_0\)</span> contains contemporaneous effects with certain zero restrictions (exclusion restrictions). - <span class="math inline">\(B_+\)</span> is the matrix comprising the intercept and coefficients of lagged variables. - <span class="math inline">\(X_t\)</span>includes a constant and lagged values of ( Y ). - <span class="math inline">\(u_t\)</span> is the error term assumed to be normally distributed.</p>
</section>
<section id="exclusion-restrictions" class="level4">
<h4 class="anchored" data-anchor-id="exclusion-restrictions">Exclusion Restrictions</h4>
<p>We have specified that each row <span class="math inline">\(n\)</span> of <span class="math inline">\(B_0\)</span> can be represented as a product of unrestricted coefficients <span class="math inline">\(b_n\)</span> and a fixed matrix <span class="math inline">\(V_n\)</span> of zeros and ones, applying structural constraints to the model.</p>
</section>
<section id="likelihood-function" class="level4">
<h4 class="anchored" data-anchor-id="likelihood-function">Likelihood Function</h4>
<p>The likelihood function for the model incorporates the determinants and exponentials of quadratic forms, which reflect the usual Gaussian assumptions for the innovations.</p>
<p>The likelihood function usning the Normal-Generalized-Normal (NGN) distribution is detailed below:</p>
<p><span class="math display">\[
L(B_+, B_0 \mid Y, X) = \left| \det (B_0) \right|^T \exp \left( -\frac{1}{2} \sum_{n=1}^N \left( b_n V_n Y - B_n X \right) \left( b_n V_n Y - B_n X \right)' \right)
\]</span></p>
<p>Expanded Expression</p>
<p>Expanding the expression within the exponential term:</p>
<p><span class="math display">\[
\sum_{n=1}^N \left( b_n V_n Y Y' V_n' b_n' - 2 b_n V_n Y X' B_n' + B_n X X' B_n' \right)
\]</span></p>
<p>And further:</p>
<p><span class="math display">\[
\begin{aligned}
    b_n V_n Y Y' V_n' b_n' - 2 b_n V_n Y X' B_n' + B_n X X' B_n' &amp;= b_n V_n \left( Y Y' - Y X' (X X')^{-1} X Y' \right) V_n' b_n' \\
    &amp;\quad + (B_n - b_n V_n \hat{A}) (X X') (B_n - b_n V_n \hat{A})'
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\hat{A} = YX' (XX')^{-1}\)</span>.</p>
<p>Likelihood Function Simplification</p>
<p>The simplified likelihood function can then be presented as:</p>
<p><span class="math display">\[
L(B_+, B_0 \mid Y, X) \sim \mathcal{NGN} \left( \hat{A}, (X X')^{-1}, (Y Y' - Y X' (X X')^{-1} X Y')^{-1}, T + N \right)
\]</span></p>
</section>
<section id="prior-and-posterior-distributions" class="level4">
<h4 class="anchored" data-anchor-id="prior-and-posterior-distributions">Prior and Posterior Distributions</h4>
<p>The model uses a Normal-generalized-normal (NGN) distribution approach for the priors. The likelihood and priors are combined to form the posterior distributions, which are sampled using Gibbs sampling.</p>
<p>Natural-Conjugate Prior</p>
<p>The NGN distribution as a natural-conjugate prior:</p>
<p><span class="math display">\[
p(B_+, B_0) \sim \mathcal{NGN} \left( B, \Omega, S, \nu \right)
\]</span></p>
<p><span class="math display">\[p(B_+, B_0) = \prod_{n=1}^N p(B_n \mid b_n) \cdot p(b_1, \ldots, b_N)
\]</span></p>
<p><span class="math display">\[p(B_n \mid b_n) \sim \mathcal{N}_K \left( b_n V_n B, \Omega \right)
\]</span></p>
<p><span class="math display">\[p(b_1, \ldots, b_N) \propto \left| \det(B_0) \right|^{\nu-N} \exp \left( -\frac{1}{2} \sum_{n=1}^N b_n V_n S^{-1} V_n' b_n' \right)
\]</span></p>
<p>Therefore,</p>
<p><span class="math display">\[
\begin{aligned}
p(B^+; B_0) &amp;= \left| \det(B_0) \right|^{\underline{\nu}-N} \exp \left\{ -\frac{1}{2} \sum_{n=1}^{N} b_n V_n \underline{S}^{-1} V_n^T b_n^T \right\} \\
&amp;\quad \times \exp \left\{ -\frac{1}{2} \sum_{n=1}^{N} (B_n - b_n V_n \underline{B}) \ \ \underline{\Omega}^{-1} \ \ (B_n - b_n V_n \underline{B})^T \right\}
\end{aligned}
\]</span></p>
<p>Posterior Distribution</p>
<p>Combining the likelihood and the prior, the posterior distribution:</p>
<p><span class="math display">\[
p(B_+, B_0 \mid Y, X) \propto L(Y \mid B_+, B_0, X) \cdot p(B_+, B_0)
\]</span></p>
<p><span class="math display">\[
\begin{align*}
= \left| \det (B_0) \right|^{T+\nu-N} \exp \Bigg( -\frac{1}{2} \sum_{n=1}^N \Bigg( &amp; b_n V_n Y Y' V_n' b_n' - 2 b_n V_n Y X' B_n' + B_n X X' B_n' \\
&amp; + b_n V_n S^{-1} V_n' b_n' + B_n \Omega^{-1} B_n' \\
&amp; - 2 b_n V_n B \Omega^{-1} B_n' + b_n V_n B \Omega^{-1} B' V_n' b_n'
\Bigg) \Bigg)
\end{align*}
\]</span></p>
<p>The resulting posterior parameters are as follow:</p>
<p><span class="math display">\[
\bar{\Omega} = [XX^T+\underline{{\Omega}} \ ]^{-1}
\]</span></p>
<p><span class="math display">\[
\bar{B} = [YX^T+\underline{B{\Omega}}^{-1}]\bar{\Omega}
\]</span></p>
<p><span class="math display">\[
\bar{S} = [YY^T+\underline{S}^{-1}+ \underline{B{\Omega}}^{-1} \underline{B}^T - \overline{B{\Omega}}^{-1} \bar{B}]^{-1}
\]</span> <span class="math display">\[
\bar{\nu} = T + \underline{\nu}
\]</span></p>
<p>Using these formulas we can proceed to sample using the Gibbs sampling procedure.</p>
</section>
<section id="gibbs-sampling-procedure" class="level4">
<h4 class="anchored" data-anchor-id="gibbs-sampling-procedure">Gibbs Sampling Procedure</h4>
<p>Gibbs sampling for this model involves: 1. <strong>Sampling the unrestricted coefficients <span class="math inline">\(b_n\)</span></strong> from their conditional distributions given the data and all other parameters. 2. <strong>Sampling <span class="math inline">\(B_+\)</span></strong>, considering the latest draws of <span class="math inline">\(b_n\)</span> and the data.</p>
</section>
<section id="steps-to-implement-in-r" class="level4">
<h4 class="anchored" data-anchor-id="steps-to-implement-in-r">Steps to Implement in R</h4>
<p>To estimate this model in R, you would generally need to:</p>
<ol type="1">
<li><strong>Define the Model Structure:</strong>
<ul>
<li>We set up matrices <span class="math inline">\(B_0\)</span> and <span class="math inline">\(B_+\)</span> based on the given structure and exclusion restrictions.</li>
<li>We prepare the data matrices <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>.</li>
</ul></li>
<li><strong>Initialize Parameters:</strong>
<ul>
<li>We initialize <span class="math inline">\(B_0\)</span>, <span class="math inline">\(B_+\)</span>, and any other matrices or parameters required for the Gibbs sampling.</li>
</ul></li>
<li><strong>Implement Gibbs Sampler:</strong>
<ul>
<li>We write loops to update each parameter iteratively based on its conditional posterior distribution. This includes:
<ul>
<li>Computing residuals and other derived quantities needed to sample <span class="math inline">\(b_n\)</span> and <span class="math inline">\(B_+\)</span>.</li>
<li>Drawing from the conditional distributions using function <code>rmvnorm</code> for multivariate normal distributions.</li>
</ul></li>
</ul></li>
<li><strong>Normalize and Summarize Results:</strong>
<ul>
<li>After obtaining the draws, we normalize and summarize the posterior distributions to get estimates and credible intervals for the parameters.</li>
</ul></li>
</ol>
</section>
</section>
<section id="model-testing-using-a-random-walk" class="level3">
<h3 class="anchored" data-anchor-id="model-testing-using-a-random-walk">Model Testing Using A Random Walk</h3>
<p>We use a random walk to generate a <span class="math inline">\(Y\)</span> matrix with one lag, and with 300 observations over four variables, to check whether the estimation algorithm is able to reproduce the random walk structure. In other words, we expect that <span class="math inline">\(B_0\)</span> will equal an identity matrix, the intercept will equal zero, and the remaining part of the <span class="math inline">\(B_+\)</span> matrix will also be an identity matrix.</p>
<p>We used 1000 iterations for the burn-in phase to allow the algorithm to converge, then used 5000 iteration for the estimation.</p>
<p>The estimated <span class="math inline">\(B_0\)</span> and <span class="math inline">\(B_+\)</span> are shown below.</p>
<p>There is a clear convergence of the diagonal of each matrix towards one. The other elements in these matrices are also approaching zero. We have enough evidence to see that the algorithm is able to estimate the random walk process.</p>
</section>
<section id="estimation-of-the-basic-model" class="level3">
<h3 class="anchored" data-anchor-id="estimation-of-the-basic-model">Estimation of the Basic Model</h3>
<p>We now repeat the same steps above to estimate the <span class="math inline">\(B_0\)</span> and <span class="math inline">\(B_+\)</span> matrices for the basic model.</p>
</section>
<section id="model-extension-i-solving-the-identification-problem-using-a-non-normality-approach" class="level3">
<h3 class="anchored" data-anchor-id="model-extension-i-solving-the-identification-problem-using-a-non-normality-approach">Model Extension I: Solving the Identification Problem Using a Non-Normality Approach</h3>
<p>We use a t-distribution to model the error terms. Given difficulties with a direct estimation of the t-distribution, we proceed as follows.</p>
<p>The current approach is as follows:</p>
<p><span class="math display">\[
\begin{aligned}
p(B_0, B_+, \lambda \mid Y, X) &amp;\propto L(Y \mid X, B_0, B_+, \lambda) \ \ p(B_0, B_+, \lambda) \\
&amp;= L(Y \mid X, B_0, B_+, \lambda) \ \ p(B_0, B_+) \ \ p(\lambda)
\end{aligned}
\]</span></p>
<p>Where, as under the basic model:</p>
<p><span class="math display">\[
\begin{aligned}
p(B^+; B_0) &amp;= \left| \det(B_0) \right|^{\underline{\nu}-N} \exp \left\{ -\frac{1}{2} \sum_{n=1}^{N} b_n V_n \underline{S}^{-1} V_n^T b_n^T \right\} \\
&amp;\quad \times \exp \left\{ -\frac{1}{2} \sum_{n=1}^{N} (B_n - b_n V_n \underline{B}) \ \ \underline{\Omega}^{-1} \ \ (B_n - b_n V_n \underline{B})^T \right\}
\end{aligned}
\]</span></p>
<p>To evaluate the overall kernel for the extended Bayesian Structural Vector Autoregression (SVAR) model where the error term <span class="math inline">\(u_t\)</span> follows a distribution <span class="math inline">\(N(0, \lambda I_N)\)</span> and <span class="math inline">\(\lambda\)</span> itself is distributed according to an Inverse Gamma square (IG2) with parameters <span class="math inline">\(\nu, \nu\)</span>, we need to account for the complexity added by this distribution of the error variance. This changes how the kernel of the likelihood function is formulated and combined with the prior.</p>
</section>
<section id="step-1-formulating-the-kernel-of-the-likelihood-function" class="level3">
<h3 class="anchored" data-anchor-id="step-1-formulating-the-kernel-of-the-likelihood-function">Step 1: Formulating the Kernel of the Likelihood Function</h3>
<p>With the error term <span class="math inline">\(u_t \sim N(0, \lambda I_N)\)</span>, the likelihood function’s kernel, incorporating the variance parameter <span class="math inline">\(\lambda\)</span>, becomes: <span class="math display">\[
L(Y \mid X, B_0, B_+, \lambda) = \text{det}(B_0)^T \exp\left(-\frac{1}{2\lambda} \sum_{n=1}^N (b_nV_nY - B_nX)(b_nV_nY - B_nX)^T\right)
\]</span></p>
</section>
<section id="step-2-estimating-lambda" class="level3">
<h3 class="anchored" data-anchor-id="step-2-estimating-lambda">Step 2: Estimating <span class="math inline">\(\lambda\)</span></h3>
<p>Since <span class="math inline">\(\lambda\)</span> is a random variable following <span class="math inline">\(\lambda \sim IG2(\nu, \nu)\)</span>, its effect can be sampled from the density function for <span class="math inline">\(\lambda\)</span>:</p>
<p><span class="math display">\[
p(\lambda) = \frac{(\psi/2)^{\psi/2}}{\Gamma(\psi/2)} \lambda^{-(\psi/2+1)} \exp\left(-\frac{\psi}{2\lambda}\right)
\]</span></p>
<p>We can use the rinvgamma() function to sample this <span class="math inline">\(\lambda\)</span>. In the estimation process for this extended model, we sample 5000 times from the IG2 distribution and use the mean value for <span class="math inline">\(\lambda\)</span>.</p>
</section>
<section id="step-3-evaluating-the-kernel" class="level3">
<h3 class="anchored" data-anchor-id="step-3-evaluating-the-kernel">Step 3: Evaluating the Kernel</h3>
<p>We use the posterior degrees of freedom to estimate the posterior variance of the error terms:</p>
<p><span class="math display">\[
\bar{\nu} = T + \underline{\nu}
\]</span></p>
<p><span class="math display">\[
\bar{\lambda} = \operatorname{IG2}({\psi}, {\psi})
\]</span></p>
</section>
<section id="step-4-combining-with-the-prior" class="level3">
<h3 class="anchored" data-anchor-id="step-4-combining-with-the-prior">Step 4: Combining with the Prior</h3>
<p>Assuming the prior <span class="math inline">\(p(B^+; B_0)\)</span> as given or formulated according to specific assumptions (such as independence, Gaussian priors for coefficients, etc.), the full posterior kernel combining this likelihood with the prior can be approached as:</p>
<p><span class="math display">\[
p(B_+; B_0; \lambda \mid Y; X) \propto p(Y \mid X, B_+, B_0, \lambda) \times p(B_+; B_0 \mid \lambda) \times p(\lambda \mid \nu) p
\]</span></p>
<p>This expression must often be evaluated or sampled using computational Bayesian techniques, such as Markov Chain Monte Carlo (MCMC), especially given the integrative step required for <span class="math inline">\(\lambda\)</span>.</p>
<p>We can obtain the following posterior formulas similar to the basic model. Note that we use <span class="math inline">\(\underline{\Omega} = \underline{\lambda\Omega}\)</span> in the following equations:</p>
<p><span class="math display">\[
\bar{\Omega} =  [\bar{\lambda}^{-1} \ XX^T+ \underline{{\Omega}} \ ]^{-1}
\]</span></p>
<p><span class="math display">\[
\bar{B} =  [\bar{\lambda}^{-1} \ YX^T+\underline{B{\Omega}}^{-1}] \ \bar{\Omega}
\]</span></p>
<p><span class="math display">\[
\bar{S} = [\bar{\lambda}^{-1} \ YY^T+\underline{S}^{-1}+ \underline{B{\Omega}}^{-1} \underline{B}^T - \overline{B{\Omega}}^{-1} \bar{B} + \psi]^{-1}
\]</span></p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Standard deviation of the model B0:
         [,1]      [,2]      [,3]       [,4]
[1,] 2.365440 0.0000000 0.0000000 0.00000000
[2,] 4.111509 0.1123536 0.0000000 0.00000000
[3,] 3.436968 0.1573530 0.3768645 0.00000000
[4,] 3.299896 0.1629621 0.5287348 0.09292176</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Extension I Model Normalized B0 matrix"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1]      [,2]     [,3]     [,4]
[1,] 41.667057 0.0000000 0.000000 0.000000
[2,]  3.580393 1.7884485 0.000000 0.000000
[3,]  5.937117 0.5276303 6.814657 0.000000
[4,] -5.024743 0.1662390 2.685142 1.728387</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Significance for B0 Matrix:"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1]  [,2]  [,3]  [,4] 
[1,] "***" "NA"  "NA"  "NA" 
[2,] ""    "***" "NA"  "NA" 
[3,] "*"   "***" "***" "NA" 
[4,] ""    ""    "***" "***"</code></pre>
</div>
</div>
</section>
<section id="second-extension-estimating-nu" class="level3">
<h3 class="anchored" data-anchor-id="second-extension-estimating-nu">Second Extension: Estimating <span class="math inline">\(\nu\)</span></h3>
<p>Following <span class="citation" data-cites="Lee2022">Lee (<a href="#ref-Lee2022" role="doc-biblioref">2022</a>)</span> we use a Metropolis-Hastings Algorithm to estimate <span class="math inline">\(\nu\)</span> and impose a vmode value corresponding to the t-distribution range <span class="math inline">\((0, 25)\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/Plotting the IRF response for the model-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>The overall kernel for this extended model encapsulates to the random variance <span class="math inline">\(\lambda\)</span>. This allows for a more robust handling of heteroscedasticity and potential non-stationarities in the error terms, offering nuanced insights into the dynamics under study.</p>
<p>In the basic model, all USD Index contemporaneous coefficients are not statistically significant at the standard levels. On the other hand, all these coefficients in the extended model are statistically significant at the 5% level.</p>
<p>The results suggest the following elasticities. According to the basic model, a weaker Dixie is likely to overheat the Australian economy: a drop of 1 per cent in the USD Index would result in roughly 1 per cent increase in inflation, roughly unchanged unemployment, and roughly 1% increase in the GDP growth rate.</p>
<p>On the other hand, the expanded model suggests that a weakening Dixie would result in an untraditional condition in the Australian economy: 1 per cent decrease in the USD Index would result is roughly 0.7 per cent increase in inflation, roughly 1 per cent increase in unemployment, and roughly 1 per cent increase in the GDP growth rate.</p>
<p>As to the second extension, where <span class="math inline">\(\nu\)</span> is a hyperparameter, this model suggests that a weakening Dixie would result in stagflation in Australia: 1 per cent decrease in the USD Index would result is roughly 3 per cent increase in inflation, roughly 0.7 per cent increase in unemployment, and roughly 3 per cent decrease in the GDP growth rate.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Bhuiyan2012" class="csl-entry" role="listitem">
Bhuiyan, R. 2012. <span>“Monetary Transmission Mechanisms in a Small Open Economy: A Bayesian Structural VAR Approach.”</span> <em>Canadian Journal of Economics</em> 45 (3): 1037–61.
</div>
<div id="ref-Chen2024" class="csl-entry" role="listitem">
Chen, J. 2024. <span>“What Is the u.s. Dollar Index (USDX) and How to Trade It.”</span> Investopedia. 2024. <a href="https://www.investopedia.com/terms/u/usdx.asp">https://www.investopedia.com/terms/u/usdx.asp</a>.
</div>
<div id="ref-Chen2004" class="csl-entry" role="listitem">
Chen, J., M. Naylor, and X. Lu. 2004. <span>“Some Insights into the Foreign Exchange Pricing Puzzle: Evidence from a Small Open Economy.”</span> <em>Pacific-Basin Finance Journal</em> 12 (1): 41–64.
</div>
<div id="ref-Lee2022" class="csl-entry" role="listitem">
Lee, Se Yoon. 2022. <span>“The Use of a Long-Normal Prior for the Student t-Distribution.”</span> <em>Xioms</em> 11 (462).
</div>
<div id="ref-RBA2024d" class="csl-entry" role="listitem">
Reserve Bank of Australia. 2024a. <span>“F12 Table, Exchange Rates, Series ID FUSXRTWI.”</span> <a href="https://www.rba.gov.au/statistics/tables/" class="uri">https://www.rba.gov.au/statistics/tables/</a>. 2024.
</div>
<div id="ref-RBA2024c" class="csl-entry" role="listitem">
———. 2024b. <span>“G1 Table, Infaltion and Inflation Expectations, Series ID GCPIAGYP.”</span> <a href="https://www.rba.gov.au/statistics/tables/" class="uri">https://www.rba.gov.au/statistics/tables/</a>. 2024.
</div>
<div id="ref-RBA2024a" class="csl-entry" role="listitem">
———. 2024c. <span>“H1 Table, GDP Growth Rate, Series ID GGDPCVGDPY.”</span> <a href="https://www.rba.gov.au/statistics/tables/" class="uri">https://www.rba.gov.au/statistics/tables/</a>. 2024.
</div>
<div id="ref-RBA2024b" class="csl-entry" role="listitem">
———. 2024d. <span>“H5 Table, Labour Force, Series ID GLFSURSA.”</span> <a href="https://www.rba.gov.au/statistics/tables/" class="uri">https://www.rba.gov.au/statistics/tables/</a>. 2024.
</div>
<div id="ref-Waggoner&amp;Zha2003" class="csl-entry" role="listitem">
Waggoner, D., and T. Zha. 2003. <span>“A Gibbs Sampler for Structural Vector Autoregressions.”</span> <em>Journal of Economic Dynamics &amp; Control</em> 28 (2): 349–66.
</div>
<div id="ref-wozniakBsvarsBayesianEstimation2022" class="csl-entry" role="listitem">
Woźniak, Tomasz. 2022. <em>Bsvars: Bayesian Estimation of Structural Vector Autoregressive Models</em>. R Package. <a href="https://cran.r-project.org/package=bsvars">https://cran.r-project.org/package=bsvars</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>